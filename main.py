import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import random

print("üöÄ –ó–ê–ü–£–°–ö –ü–†–û–ï–ö–¢–ê")
print("=" * 50)

# –î–µ–≤–∞–π—Å –∏ —Å–∏–¥—ã –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

# CNN –º–æ–¥–µ–ª—å
class ImprovedCNN(nn.Module):
    def __init__(self):
        super(ImprovedCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.5)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è
        self._fc_size = None
        self.fc1 = None
        self.fc2 = nn.Linear(128, 10)
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ö—É–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è
        self.gradients = None
        self.activations = None
        self.conv3.register_forward_hook(self.forward_hook)
        # register_backward_hook —É—Å—Ç–∞—Ä–µ–ª; –∏—Å–ø–æ–ª—å–∑—É–µ–º full_backward_hook
        self.conv3.register_full_backward_hook(self.backward_hook)

    def forward_hook(self, module, input, output):
        self.activations = output

    def backward_hook(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def _calculate_fc_size(self, x):
        # –ü—Ä–æ–±–Ω—ã–π forward pass –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv3(x))
        x = self.dropout1(x)
        return x.view(x.size(0), -1).size(1)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)  # 28x28 -> 14x14
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)  # 14x14 -> 7x7
        x = F.relu(self.conv3(x))  # 7x7
        x = self.dropout1(x)
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ fc1 –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
        if self.fc1 is None:
            fc_size = x.view(x.size(0), -1).size(1)
            self.fc1 = nn.Linear(fc_size, 128).to(x.device)
            self._fc_size = fc_size
        
        x = x.view(-1, self._fc_size)
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = self.fc2(x)
        return x  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–æ–≥–∏—Ç—ã, –±–µ–∑ softmax

# –ù–∞—Å—Ç–æ—è—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Grad-CAM
class GradCAM:
    def __init__(self, model):
        self.model = model
        self.model.eval()
        
    def generate_cam(self, images, target_class=None):
        batch_size = images.shape[0]
        cam_maps = []
        
        for i in range(batch_size):
            image = images[i].unsqueeze(0).to(device)
            image.requires_grad_()
            
            # Forward pass
            output = self.model(image)
            
            # –í—ã–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if target_class is None:
                class_idx = output.argmax(dim=1).item()
            else:
                class_idx = (target_class[i] if isinstance(target_class, (list, tuple, np.ndarray)) else int(target_class))
            
            # Backward pass –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
            self.model.zero_grad()
            one_hot = torch.zeros_like(output)
            one_hot[0, class_idx] = 1
            output.backward(gradient=one_hot)
            
            # –ü–æ–ª—É—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
            gradients = self.model.gradients[0].detach().cpu().numpy()
            activations = self.model.activations[0].detach().cpu().numpy()
            
            # –í—ã—á–∏—Å–ª—è–µ–º weights (—Å—Ä–µ–¥–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–∑–º–µ—Ä–µ–Ω–∏—è–º)
            weights = np.mean(gradients, axis=(1, 2))
            
            # –í—ã—á–∏—Å–ª—è–µ–º CAM
            cam = np.zeros(activations.shape[1:], dtype=np.float32)
            for j, w in enumerate(weights):
                cam += w * activations[j]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º ReLU –∏ —Ä–µ—Å–∞–π–∑–∏–º –∫ —Ä–∞–∑–º–µ—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            cam = np.maximum(cam, 0)
            if cam.max() > 0:
                cam = cam / cam.max()  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            else:
                cam = np.zeros_like(cam)
            
            # –†–µ—Å–∞–π–∑ –¥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é torch
            cam_tensor = torch.from_numpy(cam).float().unsqueeze(0).unsqueeze(0)
            cam_resized = F.interpolate(cam_tensor, size=(28, 28), mode='bilinear', align_corners=False)
            cam = cam_resized.squeeze().numpy()
            
            cam_maps.append(cam)
            
        return np.array(cam_maps)

# –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
def train_model():
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ MNIST...")
    
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
    
    test_dataset = datasets.MNIST('./data', train=False, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=True)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = ImprovedCNN().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)
    
    print("–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º fc1 —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ–±–Ω–æ–≥–æ forward pass
    with torch.no_grad():
        dummy_input = torch.randn(1, 1, 28, 28, device=device)
        _ = model(dummy_input)
    
    for epoch in range(10):  # –ë–æ–ª—å—à–µ —ç–ø–æ—Ö –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
        model.train()
        total_loss = 0
        for batch_idx, (data, target) in enumerate(train_loader):
            data = data.to(device)
            target = target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = F.cross_entropy(output, target)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
            
            if batch_idx % 100 == 0:
                print(f'–≠–ø–æ—Ö–∞ {epoch+1}, –ë–∞—Ç—á {batch_idx}, Loss: {loss.item():.4f}')
        
        scheduler.step()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                data = data.to(device)
                target = target.to(device)
                output = model(data)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
        
        accuracy = 100. * correct / len(test_loader.dataset)
        print(f'–≠–ø–æ—Ö–∞ {epoch+1}, –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2f}%')
        
        if accuracy >= 80.0:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–π —Ç–æ—á–Ω–æ—Å—Ç–∏
            break
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    model.eval()
    test_loss = 0
    correct = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data = data.to(device)
            target = target.to(device)
            output = model(data)
            test_loss += F.cross_entropy(output, target, reduction='sum').item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    test_loss /= len(test_loader.dataset)
    accuracy = 100. * correct / len(test_loader.dataset)
    
    print(f'\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!')
    print(f'–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–º–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {accuracy:.2f}%')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    torch.save(model.state_dict(), 'mnist_cnn.pth')
    
    return model

def apply_mask(image, mask, threshold=0.3):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∞—Å–∫—É –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é"""
    image_np = image.squeeze().cpu().numpy()
    mask_binary = mask > threshold
    masked_image = image_np * mask_binary
    return torch.from_numpy(masked_image).unsqueeze(0).float()

# –§—É–Ω–∫—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
def visualize_results(model, num_images=5):
    print("\nüé® –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
    
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    test_dataset = datasets.MNIST('./data', train=False, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=num_images, shuffle=True)
    
    # –ë–µ—Ä–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    data_iter = iter(test_loader)
    images, labels = next(data_iter)
    images = images.to(device)
    labels = labels.to(device)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–ª–æ–≥–∏—Ç—ã)
    model.eval()
    with torch.no_grad():
        outputs = model(images)
        predictions = outputs.argmax(dim=1)
        probabilities = F.softmax(outputs, dim=1)
    
    # –°–æ–∑–¥–∞–µ–º Grad-CAM
    gradcam = GradCAM(model)
    cam_maps = gradcam.generate_cam(images)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º
    fig, axes = plt.subplots(num_images, 4, figsize=(15, 3 * num_images))
    
    if num_images == 1:
        axes = axes.reshape(1, -1)
    
    for i in range(num_images):
        # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        axes[i, 0].imshow(images[i].detach().cpu().squeeze(), cmap='gray')
        axes[i, 0].set_title(f'–ò—Å—Ç–∏–Ω–∞: {labels[i].item()}\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions[i].item()}\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {probabilities[i, predictions[i]].item():.3f}')
        axes[i, 0].axis('off')
        
        # Heatmap
        axes[i, 1].imshow(cam_maps[i], cmap='jet')
        axes[i, 1].set_title('Grad-CAM Heatmap')
        axes[i, 1].axis('off')
        
        # –ù–∞–ª–æ–∂–µ–Ω–∏–µ
        axes[i, 2].imshow(images[i].detach().cpu().squeeze(), cmap='gray')
        axes[i, 2].imshow(cam_maps[i], cmap='jet', alpha=0.5)
        axes[i, 2].set_title('Grad-CAM –Ω–∞–ª–æ–∂–µ–Ω–∏–µ')
        axes[i, 2].axis('off')
        
        # –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        masked_image = apply_mask(images[i].detach().cpu(), cam_maps[i])
        axes[i, 3].imshow(masked_image.squeeze(), cmap='gray')
        axes[i, 3].set_title('–ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
        axes[i, 3].axis('off')
    
    plt.tight_layout()
    plt.savefig('gradcam_results.png', dpi=120, bbox_inches='tight')
    plt.show()
    
    return images.cpu(), labels.cpu(), predictions.cpu(), cam_maps

# –†–∞—Å—á–µ—Ç Fidelity (–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
def calculate_fidelity(model, images, labels, cam_maps):
    print("\n–í—ã—á–∏—Å–ª—è–µ–º Fidelity...")
    
    model.eval()
    fidelities = []
    
    with torch.no_grad():
        for i in range(len(images)):
            img = images[i].unsqueeze(0).to(device)
            # –ö–ª–∞—Å—Å –±–µ—Ä—ë–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –º–æ–¥–µ–ª—å—é –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
            output_orig_all = model(img)
            class_idx = output_orig_all.argmax(dim=1).item()
            logit_orig = output_orig_all[0, class_idx].item()
            
            # –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–Ω–∞ CPU), –ø–µ—Ä–µ–Ω–µ—Å—ë–º –Ω–∞ –¥–µ–≤–∞–π—Å
            masked_image = apply_mask(images[i], cam_maps[i]).unsqueeze(0).to(device)
            output_masked_all = model(masked_image)
            logit_masked = output_masked_all[0, class_idx].item()
            
            # Fidelity = f(x) - f(x ‚äô m) –¥–ª—è —Ç–æ–≥–æ –∂–µ –∫–ª–∞—Å—Å–∞
            fidelity = logit_orig - logit_masked
            fidelities.append(fidelity)
            
            print(f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}: Fidelity = {fidelity:.4f} '
                  f'(logit_orig: {logit_orig:.4f}, logit_masked: {logit_masked:.4f})')
    
    mean_fid = np.mean(fidelities)
    var_fid = np.var(fidelities)
    
    print(f'\n–°—Ä–µ–¥–Ω—è—è Fidelity: {mean_fid:.4f}')
    print(f'–î–∏—Å–ø–µ—Ä—Å–∏—è Fidelity: {var_fid:.4f}')
    
    return fidelities, mean_fid, var_fid

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():

    
    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–ª–∏ –æ–±—É—á–∞–µ–º –Ω–æ–≤—É—é
    try:
        model = ImprovedCNN().to(device)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –≤–µ—Å–æ–≤
        with torch.no_grad():
            dummy_input = torch.randn(1, 1, 28, 28, device=device)
            _ = model(dummy_input)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ (—Å —É—á—ë—Ç–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞)
        state = torch.load('mnist_cnn.pth', map_location=device)
        model.load_state_dict(state)
        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        test_dataset = datasets.MNIST('./data', train=False, transform=transform)
        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=True)
        
        model.eval()
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                data = data.to(device)
                target = target.to(device)
                output = model(data)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
        
        accuracy = 100. * correct / len(test_loader.dataset)
        print(f'–¢–æ—á–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {accuracy:.2f}%')
        
        if accuracy < 80.0:
            print('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∏–∂–µ 80%, –ø–µ—Ä–µ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å...')
            model = train_model()
            
    except Exception as e:
        print(f"–û–±—É—á–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å. –ü—Ä–∏—á–∏–Ω–∞: {e}")
        model = train_model()
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    images, labels, predictions, cam_maps = visualize_results(model, 5)
    
    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    fidelities, mean_fid, var_fid = calculate_fidelity(model, images, labels, cam_maps)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print(f"–°—Ä–µ–¥–Ω—è—è Fidelity: {mean_fid:.4f}")
    print(f"–î–∏—Å–ø–µ—Ä—Å–∏—è Fidelity: {var_fid:.4f}")
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'gradcam_results.png'")

if __name__ == "__main__":
    main()